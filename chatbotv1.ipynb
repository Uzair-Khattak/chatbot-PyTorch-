{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#importing libraries\nimport numpy as np\nimport nltk\nimport json\n#for deeplearning\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset,DataLoader","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now defining some functions\ndef tokenize(my_sentence):\n    return nltk.word_tokenize(my_sentence)\n\n# my_sentence=\"I LOVE YOU\"\n# print(tokenize(my_sentence))\n\n# nltk.download('punkt')\nfrom nltk.stem.porter import PorterStemmer\nstemmer= PorterStemmer()\ndef stemming(single_word):\n    return stemmer.stem(single_word.lower())\n\n# my_array_to_be_stemmed=[\"Organize\",\"organizing\",\"organizer\"]\n# my_stemmed_array=[stemming(x) for x in my_array_to_be_stemmed]\n\ndef bag_of_words_converter(tokenized_stemmed_sentence,bag_of_words_original):\n    \n    vector=np.zeros(len(bag_of_words_original),dtype=np.float32)\n    for word in tokenized_stemmed_sentence:\n        if word in bag_of_words_original:\n#             print('came here')\n            my_index=bag_of_words_original.index(word)\n            vector[my_index]=1\n    return vector\n# sentence = [\"hello\", \"how\", \"are\", \"you\"]\n# words = [\"hi\", \"hello\", \"I\", \"you\", \"bye\", \"thank\", \"cool\"]\n# sentence=[stemming(w) for w in sentence]\n# print(bag_of_words_converter(sentence,words))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now reading our data from the disk\nwith open('../input/my-data1212/intents.json','r') as f:\n    intents=json.load(f)\n#now preprocessing the data to extract labels and examples\n#so we are now in the *preprocessing of data* phase\n#we need to make training data\n#iterate through json file to retrieve tags and patterns\ntext_tag_tuple=[]\ntags=[]\nall_words_array=[]\nfor intent in intents[\"intents\"]:\n    tag=intent[\"tag\"]\n    tags.append(tag)\n    for pattern in intent[\"patterns\"]:\n        tokenized_sentence=tokenize(pattern)\n        text_tag_tuple.append((tokenized_sentence,tag))\n        all_words_array.extend(tokenized_sentence)\n\n\n#now making sorted and unieqe set of all_words array\n#as well for the tags\nother_characters=['?','!','.', ',']\ntags=sorted(set(tags))\n\n#now time to stem each word as well as remove the other characters like ? , ! etc\nall_words_array=[stemming(w) for w in all_words_array if w not in other_characters]\nall_words_array=sorted(set(all_words_array))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_sen=\"howsf aresafasf yousfx\"\ntok=tokenize(my_sen)\nprint(tok)\nstem_version=[stemming(w) for w in tok]\nprint(stem_version)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import glob\nx=glob.glob('../input/my-data1212/*')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now make data for pytorch to train\nX_train=[]\nY_train=[]\n\nfor (sentence,tag) in text_tag_tuple:\n    sentence=[stemming(w) for w in sentence]\n    my_converted_vector=bag_of_words_converter(sentence,all_words_array)\n    index_of_label=tags.index(tag)\n    X_train.append(my_converted_vector)\n    Y_train.append(index_of_label)\nX_train=np.array(X_train)\nY_train=np.array(Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now making dataset object for pytorch network\nclass chatbot_dataset(Dataset):\n    def __init__(self):\n        self.length_data=len(X_train)\n        self.x_data=X_train\n        self.y_data=Y_train\n    def __getitem__(self,idx):\n        return self.x_data[idx], self.y_data[idx]\n    \n    def __len__(self):\n        return len(X_train)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_created=chatbot_dataset()\ntrain_loader=DataLoader(dataset_created,batch_size=8,shuffle=True,num_workers=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now lets make the neural network\n\nclass my_network(nn.Module):\n    def __init__(self,input_size,out_classes,hidden_size):\n        super().__init__()\n        self.linear1=nn.Linear(in_features=input_size,out_features=hidden_size)\n        self.linear2=nn.Linear(in_features=hidden_size,out_features=hidden_size)\n        self.linear3=nn.Linear(in_features=hidden_size,out_features=out_classes)\n        self.relu=nn.ReLU()\n        \n    def forward(self,t):\n        t=t\n        t=self.linear1(t)\n        t=self.relu(t)\n        t=self.linear2(t)\n        t=self.relu(t)\n        t=self.linear3(t)\n\n        return t","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now defining some basic variables\ninput_size=len(all_words_array)\noutput_size=len(tags)\nhidden_size=16\n#defining loss, optimizer etc\n#Now making arguments for above ftn\n\n\nmy_model=my_network(input_size,output_size,hidden_size)\nlearning_rate1=0.003\nmy_loss=nn.CrossEntropyLoss()\nmy_optimizer=torch.optim.Adam(my_model.parameters(),lr=learning_rate1)\ndynamic_learning_rate=torch.optim.lr_scheduler.StepLR(my_optimizer,step_size=7,gamma=0.1)\ndevice=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n#now time to make the model \ndef my_train_model(model,data,optimizer,given_loss,scheduler,total_epochs=1000):\n\n    train_loss , train_acc, val_loss, val_accuracy = [],[],[],[]\n\n    my_sizes={ 'train': len(X_train)}\n    #first loop for the epochs\n    for i in range (total_epochs):\n            total_correct=0\n            for batch in data:\n                \n                \n                #now performing the forward steps \n                input_data,labels=batch\n                #put data into GPU processing if available\n                input_data=input_data.to(device)\n                labels=labels.to(device)\n                my_prediction=model(input_data)\n                #find loss\n                loss=given_loss(my_prediction,labels)\n                total_correct+=my_prediction.argmax(dim=1).eq(labels).sum().item()\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n#             if (i+1 % 100 == 0):\n            print(f'epoch {i+1}/1000,loss={loss.item():.4f}')\n            print(' Accuracy= ' +  str(total_correct/my_sizes[\"train\"]))\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trained_model=my_train_model(model=my_model.to(device),data=train_loader,\n               optimizer=my_optimizer,\n                    given_loss=my_loss,\n               scheduler=dynamic_learning_rate)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now training complete \n#implement a chat environment\nmy_model.eval()\ndevice=torch.device(\"cpu\")\nimport random\nprint('Chatbot is ready to chat with you !!! / enter \"quit\" to leave the chatting ')\nprint('lets start !')\nwhile True:\n    sentence = input('you :')\n    if sentence == \"quit\":\n        break\n    #now tokenize ,stem and feed to network\n    tokenized=tokenize(sentence)\n    stemmed=[stemming(w) for w in tokenized]\n    my_vector=bag_of_words_converter(stemmed,all_words_array)\n    \n    my_vector=torch.from_numpy(my_vector)\n    my_vector=torch.unsqueeze(my_vector,0)\n    my_vector.to(device)\n    trained_model.to(device)\n    prediction=trained_model(my_vector)\n    prediction_probabilities=torch.softmax(prediction,dim=1)\n    predicted_tag_index=prediction.argmax(dim=1).item()\n#     print(predicted_tag_index)\n    actual_tag_predicted=tags[predicted_tag_index]\n#     print(actual_tag_predicted)\n    #also checking for probability so that it doesnot give unwanted answers\n    prob=prediction_probabilities[0,predicted_tag_index]\n#     print(prob)\n    if prob<0.7:\n        print(f\"Madni_boy: Sorry, I cannot understand you...\" )\n        continue\n    \n    #now time for chatbot to give answer\n    for intent in intents[\"intents\"]:\n        if intent[\"tag\"]==actual_tag_predicted:\n            print(f\"Madni_boy:\" + str(random.choice(intent[\"responses\"])))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}